<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Causal Representation Learning | Burak Varıcı</title> <meta name="author" content="Burak Varıcı"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bvarici.github.io/projects/CRL2/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Burak Varıcı</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/Varici_CV.pdf" target="_blank" rel="noopener noreferrer">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Causal Representation Learning</h1> <p class="post-description"></p> </header> <article> <style>.button-link{display:inline-block;padding:6px 14px;margin:4px;font-size:14px;font-weight:bold;color:#6a0dad;text-decoration:none;background:transparent;border:2px solid #6a0dad;border-radius:6px;transition:all .3s ease}.button-link:hover{background:#6a0dad;color:white;box-shadow:0 3px 5px rgba(0,0,0,0.15);transform:translateY(-1px)}.button-container{text-align:center;margin-top:5px}</style> <p><strong>List of publications</strong></p> <ul> <li> <strong>Tutorials</strong>: At AAAI 2025 <a href="https://www.isg-rpi.com/_files/ugd/601e73_ccf7870865a74aa0b7f4fdc6660a168e.pdf" rel="external nofollow noopener" target="_blank">slides</a> and NASIT 2025 <a href="https://drive.google.com/file/d/1ew-BWBPFBziI_Au52i1MtRSlrFKnSFdZ/view" rel="external nofollow noopener" target="_blank">slides</a> <a href="https://mediaspace.umn.edu/media/1_thnye7es" rel="external nofollow noopener" target="_blank">video-part1</a> <a href="https://mediaspace.umn.edu/media/1_468pa4d9" rel="external nofollow noopener" target="_blank">video-part2</a> </li> <li> <a href="[aa](https://www.jmlr.org/papers/volume26/24-0194/24-0194.pdf)">Score-based Causal Representation Learning: Linear and General Transformations (JMLR)</a>: considers single-node interventions for linear and general transformations</li> <li> <a href="https://arxiv.org/abs/2510.20884" rel="external nofollow noopener" target="_blank">ROPES: Robotic Pose Estimation via Score-based Causal Representation Learning (NeurIPS’25 Workshop)</a>: an application on robotic pose estimation</li> <li> <a href="https://proceedings.mlr.press/v238/varici24a.html" rel="external nofollow noopener" target="_blank">General Identifiability and Achievability for Causal Representation Learning (AISTATS’24)</a>: considers general transformations with single-node interventions (JMLR paper significantly extends this preliminary version)</li> <li> <a href="https://openreview.net/forum?id=weemASPtzg" rel="external nofollow noopener" target="_blank">Linear Causal Representation Learning from Unknown Multi-node Interventions (NeurIPS’24)</a>: multi-node interventions on Linear CRL</li> <li> <a href="https://openreview.net/forum?id=XL9aaXl0u6&amp;noteId=0uxPDmh1nn" rel="external nofollow noopener" target="_blank">Sample Complexity of Interventional Causal Representation Learning (NeurIPS’24)</a>: sample-complexity analysis of linear CRL</li> <li> <a href="https://arxiv.org/pdf/2301.08230" rel="external nofollow noopener" target="_blank">Score-based causal representation learning with interventions</a>: very first paper which establishes the foundations of score-based CRL idea, for non-linear latent causal models and linear transforms.</li> </ul> <p>See below for a conceptual summary of this line of work, settings and key results of the papers mentioned above.</p> <h3 id="project-summary">Project summary:</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/CRL_problem-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/CRL_problem-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/CRL_problem-1400.webp"></source> <img src="/assets/img/crl_figures/CRL_problem.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="auto" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>In causal representation learning (CRL), we consider a data-generating process in which the high-dimensional observations \(X\) are generated from low-dimensional, causally-related variables \(Z\) through an unknown transformation \(g\) as \(X=g(Z)\). The causal relationships among the latent variables are captured by a directed acyclic graph (DAG) \({\cal{G}}_{Z}\) over \(Z\).</p> <p>The central goal of CRL is to use the observed data \(X\) to recover \(Z\) and \({\cal{G}}\). This process is typically facilitated by learning an inverse of the data-generating process, i.e., \(g^{-1}\) as the inverse of the unknown generative mapping \(g\). We focus on two central questions:</p> <ol> <li> <strong>Identifiability</strong>: Determining the necessary and sufficient conditions under which \({\cal{G}}\) and \(Z\) can be recovered. The scope of identifiability (e.g., node-level, perfect, partial etc.) critically depends on the extent of information available about the data and the underlying data-generation process.</li> </ol> <ol> <li> <strong>Achievability</strong>: is the notion of designing tractable algorithms that can recover \(Z\) and \(\mathcal{G}\), while maintaining identifiability guarantees. Note that identifiability results can be non-constructive, without specifying feasible algorithms. Hence, we make the distinction and aim to design practical algorithms for achieving constructive identifiability results.</li> </ol> <p><strong>Why is identifiability difficult?</strong> Identifiability is known to be impossible without additional supervision or sufficient statistical diversity among the samples of the observed data \(X\). For instance, for the true transform \(g\) and another invertible function \(a\), we have \((g \circ g^{-1})(X)=X\) and \((g \circ a^{-1}) \circ (a \circ g^{-1})(X)=X\). Hence, inverse transform \(g^{-1}\) cannot be simply inferred by enforcing perfect reconstruction of \(X\). As an extreme simplification, consider linear mixing of <em>independent</em> Gaussian variables (i.e., an empty graph). Since Gaussians are rotation-invariant, we cannot distinguish between \(Z\) and \(R \circ Z\) for any rotation matrix \(R\).</p> <p>Therefore, to ensure identifiability, we need to look for a reasonable combination of (i) assumptions on the data-generation (model class we consider), and (ii) richer observations.</p> <h3 id="interventions--multi-environments-as-diverse-data-sources">Interventions / Multi-environments as Diverse Data Sources</h3> <p>Consider observing data from multiple related environments. Typically, differences between those environments can be explained by changes in a few key factors. In other words, taking the view that high-dimensional data lie in a low-dimensional manifold, sparse changes in the low-dimensional representation can explain the differences across environments. From CRL viewpoint, these sparse changes can be formalized by <strong>interventions</strong> on the latent causal space, which provide the sufficient richer observations to enable identifiability of latent variables and graph. Specifically, in addition to observational environment, we consider a set of given interventional environments, in which a subset of nodes are intervened in each. In this framework, we only use <em>distribution level</em> information, meaning that we use the interventions as a weak form of supervision via having access to only the pair of distributions before and after an intervention (as opposed to requiring pairs of observed and intervened samples). This allows us:</p> <ul> <li>model distribution shifts via changes in causal mechanisms</li> <li>contrast interventional vs. observational distributions</li> <li>if changes are sparse, gives a natural way to restrain the solution set</li> </ul> <p>To harness the additional knowledge induced by the interventions, we developed <strong>score-based CRL</strong>. The key idea is that latent score functions (gradients of log-densities) encode intervention effects as sparse variations across environments. By linking score functions of observed data (which can be efficiently estimated even in high-dimensional settings) to latent scores, we obtain tractable learning objectives and algorithms. In short, we develop algorithms that search for representations whose inter-environment differences are maximally sparse, aligning them with the true causal mechanisms.</p> <p>The theoretical foundations of CRL have two main axes: (i) model complexity, i.e., how expressive the true causal mechanisms and the mapping from latent to observed data are; and (ii) data richness, i.e., what diversity of environments and interventions is necessary and sufficient for identifiability. This perspective clarifies which structural assumptions and data resources are needed in different regimes.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/interventional_environments-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/interventional_environments-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/interventional_environments-1400.webp"></source> <img src="/assets/img/crl_figures/interventional_environments.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="auto" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Ideally, one would prefer no restriction on intervention size, type, or knowledge. In our work, we consider a spectrum of settings to lay out the identifiability landscape and accompanying algorithms, e.g., linear vs. general transformations, single-node vs. multi-node interventions, soft vs. hard interventions. Before</p> <h3 id="score-based-crl">Score-based CRL</h3> <p>In our papers, we establish the connections between <strong>score functions</strong> (gradient of the log-density) and interventional distributions. Specifically, we show that differences in score functions across different environment pairs contain all the information about the latent DAG. Leveraging this property, we show that the data-generating process can be inverted by finding the inverse transform that minimizes the score differences in the latent space. Using this approach, we develop constructive proofs of identifiability and algorithms in various settings. To give an insight, there are two key properties of score functions that make this idea work. Denote \(s(z) = \nabla \log_z p(z)\) and \(s_X(x) = \nabla \log_x p(x)\) for observational distributions \(p(z)\) and \(p_X(x)\). Use superscript \(^m\) to denote corresponding definitions in interventional environment \({\cal E}^m\).</p> <p><strong>Score differences are sparse</strong>: Consider a single-node intervention, e.g., node $i$ is intervened in \({\cal E}^m\). Then, the score difference function \(s(z) - s^m(z)\) will be sparse, with indices of non-zero entries exactly correspond to the parents of the intervened node. This implies that given access to all single-node interventions, changes in the score functions exactly give DAG structure!</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/intervention_score_connection-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/intervention_score_connection-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/intervention_score_connection-1400.webp"></source> <img src="/assets/img/crl_figures/intervention_score_connection.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="70%" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>How can we use this property to guide our learning of an inverse transform? Consider a candidate encoder $h$, and \let $\hat{Z} = h(X)$. Intuitively, we can use the sparsity of the <em>true latent score differences</em> to find the true encoder \(g^{-1}\), i.e., the estimated latent score differences cannot be sparser than the true score differences.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/intuition-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/intuition-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/intuition-1400.webp"></source> <img src="/assets/img/crl_figures/intuition.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="70%" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Latent score differences can be computed from observed score differences</strong>: So far, the nice sparsity properties of score functions above are for latent variables, since these properties stem from the causal relationships and interventions on the latents. However, we have only access to observed \(X\) variables. In terms of pure identifiability objective, one can suggest computing the score functions of $\hat{Z}$ for every possible encoder \(h\), which is infeasible. Instead, we take a constructive approach and show that latent score differences can be computed from observed score differences using the Jacobian of \(h^{-1}\). Specifically, \(s_{\hat{Z}} ({\hat{z}}) - s_{\hat{Z}}^{m}({\hat{z}}) = J_{h^{-1}}({\hat{z}})^{\top} (s_{X} (x) - s_{X}^{m}(x))\).</p> <p><strong>How to form an objective function?</strong>: Different settings (i.e., a pair data-generation model and observed data) require different levels of algorithm design (e.g., dealing with multi-node interventions, parametric vs. nonparametric construction etc.). At their cores though, those different methods rely on the same principle of algorithmically enforcing the sparse changes on the latent mechanisms. Using the link between score functions of observed and latent variables, this principle can be summarized as learning an (encoder,decoder) pair \((f,h)\) that (i) minimizes score variations in the latents across environments, and (ii) ensures perfect reconstruction:</p> \[\mathcal{L}(h, f) = \underbrace{\mathbb{E}\!\left[\| f \circ h(x) - x \|^2\right]}_{\text{Reconstruction Loss}} + \lambda \underbrace{\left\| \mathbb{E}\!\left[ \textrm{Jac.}_f(\hat{z})^{\top} \cdot \left(\Delta s_X(x)\right) \right] - e_i \right\|^2}_{\text{Sparsity Loss}}.\] <hr> <h4 id="score-based-causal-representation-learning-linear-and-general-transformations-jmlr25">Score-based Causal Representation Learning: Linear and General Transformations (JMLR’25)</h4> <!--[[Paper]](https://arxiv.org/abs/2402.00849) [[Code]](https://github.com/acarturk-e/score-based-crl)--> <div class="button-container"> <a href="https://www.jmlr.org/papers/volume26/24-0194/24-0194.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> </div> <p>TLDR:</p> <ul> <li>Linear transform, general causal models, one single-node intervention per node.</li> <li> <strong>Hard</strong> interventions: element-wise identifiability up to scaling and perfect recovery of DAG.</li> <li> <strong>Soft</strong> interventions: identifiability up to parents. If the causal model is sufficiently nonlinear, then latent DAG is fully identified and latent variables are identified up to surrounding variables (shown to be a tight result)</li> <li>General transform: reorganization of the AISTATS paper, with additional experiments.</li> </ul> <h3 id="ropes-robotic-pose-estimation-via-score-based-causal-representation-learning-neurips25-emw-workshop">ROPES: Robotic Pose Estimation via Score-based Causal Representation Learning (NeurIPS’25 EMW Workshop)</h3> <div class="button-container"> <a href="https://arxiv.org/abs/2510.20884" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> </div> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/ropes3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/ropes3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/ropes3-1400.webp"></source> <img src="/assets/img/crl_figures/ropes3.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="70%" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>TLDR: Taking a step towards bridging the theory-practice gap in interventional CRL by applying it to robot pose estimation problem.</p> <ul> <li>Formalization: Pose estimation as a CRL problem in which robot joint angles are treated as controllable latent causal variables embedded in a larger generative mapping</li> <li>Methodology: ROPES, an autoencoder-based architecture augmented with interventional regularizers that rely on score variations upon interventions. This relies on score-based CRL algorithms.</li> <li>Empirical validation: Use common simulators with multi-joint robot and collect visual data. Showing a strong correlation between the angles recovered by ROPES and the ground truth values, verifying successful disentanglement</li> <li>No reliance on pose labels: Showing disentanglement by exploiting distributional changes and therefore requires no conventional supervision from pose labels.</li> <li>Comparison with state-of-the-art: ROPES, without using labels except a final calibration step, achieves comparable performance to state-of-the-art RoboPEPP, which uses a JEPA-based self-supervised backbone followed by supervised training to predict joint angles. Specifically, our ablation study shows that RoboPEPP requires a substantial amount of labeled data to outperform our pose-label-free CRL-based method.</li> </ul> <h4 id="linear-causal-representation-learning-from-unknown-multi-node-interventions-neurips24">Linear Causal Representation Learning from Unknown Multi-node Interventions (NeurIPS’24)</h4> <!--[[Paper]](https://openreview.net/forum?id=weemASPtzg) [[Code]](https://github.com/acarturk-e/score-based-crl) [[Poster]](https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/UMN_CRL_poster_final.pdf)--> <div class="button-container"> <a href="https://openreview.net/forum?id=weemASPtzg" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/UMN_CRL_poster_final.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Poster</a> </div> <p>TLDR:</p> <ul> <li>Linear transform, general causal models, <strong>unknown multi-node</strong> interventions. Same guarantees as single-node interventions!</li> <li> <strong>Hard</strong> interventions: element-wise identifiability up to scaling and perfect recovery of DAG.</li> <li> <strong>Soft</strong> interventions: identifiability up to ancestors</li> <li>Requirement: multi-node interventions are diverse enough, specified as having a full-rank intervention signature matrix.</li> </ul> <h4 id="sample-complexity-of-interventional-causal-representation-learning-neurips24">Sample Complexity of Interventional Causal Representation Learning (NeurIPS’24)</h4> <!--[[Paper]](https://openreview.net/forum?id=XL9aaXl0u6&noteId=0uxPDmh1nn) [[Poster]](https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/Finite_sample_CRL_poster.pdf)--> <div class="button-container"> <a href="https://openreview.net/forum?id=XL9aaXl0u6&amp;noteId=0uxPDmh1nn" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/Finite_sample_CRL_poster.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Poster</a> </div> <p>TLDR:</p> <ul> <li>Linear transform, general causal models, one <strong>single-node</strong> soft intervention per node.</li> <li>First sample complexity results for interventional CRL!</li> <li>Probably approximately correct (PAC)-identifiability via generic score estimators.</li> <li>Specific sample complexity results for an RKHS-based score estimator.</li> </ul> <h4 id="general-identifiability-and-achievability-for-causal-representation-learning-aistats24-oral">General Identifiability and Achievability for Causal Representation Learning (AISTATS’24 oral)</h4> <!--[Paper](https://proceedings.mlr.press/v238/varici24a.html) [[Code]](https://github.com/acarturk-e/score-based-CRL) [[Talk]](https://neurips.cc/virtual/2023/74252) [[Poster]](https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/AISTATS_CRL_poster.pdf)--> <div class="button-container"> <a href="https://proceedings.mlr.press/v238/varici24a.html" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://neurips.cc/virtual/2023/74252" class="button-link" rel="external nofollow noopener" target="_blank">Talk</a> <a href="https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/AISTATS_CRL_poster.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Poster</a> </div> <p>TLDR:</p> <ul> <li> <strong>General transform</strong>, general causal models, two single-node hard interventions per node suffice for element-wise identifiability (up to an intervible transform)!</li> <li>First provably correct algorithm for general transforms! Experiments with images confirm the scalability.</li> <li>Benefits: do not require faithfulness assumption of causal discovery, and do not require to know which pair of environments intervene on the same node.</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li><div class="row" style="margin-bottom: 30px;"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JMLR</abbr> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/crl_jmlr_overview-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/crl_jmlr_overview-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/crl_jmlr_overview-1400.webp"></source> <img src="/assets/img/publication_preview/crl_jmlr_overview.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="crl_jmlr_overview.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="varici2025score" class="col-sm-8"> <div class="title">Score-based causal representation learning: Linear and General Transformations</div> <div class="author"> Burak Varıcı*, Emre Acartürk*, Karthikeyan Shanmugam, Abhishek Kumar, and Ali Tajer </div> <div class="periodical"> <em>Journal of Machine Learning Research</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://jmlr.org/papers/volume26/24-0194/24-0194.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/acarturk-e/score-based-crl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">varici2025score</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Score-based causal representation learning: Linear and General Transformations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}*, Burak and Acart{\"u}rk*, Emre and Shanmugam, Karthikeyan and Kumar, Abhishek and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{26}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{112}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--90}</span><span class="p">,</span>
  <span class="na">rank</span> <span class="p">=</span> <span class="s">{1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> <li><div class="row" style="margin-bottom: 30px;"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS Workshop</abbr> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ropes2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ropes2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ropes2-1400.webp"></source> <img src="/assets/img/publication_preview/ropes2.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ropes2.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kulkarni2025ropes" class="col-sm-8"> <div class="title">ROPES: Robotic Pose Estimation via Score-based Causal Representation Learning</div> <div class="author"> Pranamya Prashant Kulkarni, Puranjay Datta, <em>Burak Varıcı</em>, Emre Acartürk, Karthikeyan Shanmugam, and Ali Tajer </div> <div class="periodical"> <em>arXiv:2510.20884, (NeurIPS 2025 Workshop on Embodied World Models for Decision Making)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2510.20884" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Causal representation learning (CRL) has emerged as a powerful unsupervised framework that (i) disentangles the latent generative factors underlying high-dimensional data, and (ii) learns the cause-and-effect interactions among the disentangled variables. Despite extensive recent advances in identifiability and some practical progress, a substantial gap remains between theory and real-world practice. This paper takes a step toward closing that gap by bringing CRL to robotics, a domain that has motivated CRL. Specifically, this paper addresses the well-defined robot pose estimation – the recovery of position and orientation from raw images – by introducing Robotic Pose Estimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES embodies the essence of interventional CRL by identifying those generative factors that are actuated: images are generated by intrinsic and extrinsic latent factors (e.g., joint angles, arm/limb geometry, lighting, background, and camera configuration) and the objective is to disentangle and recover the controllable latent variables, i.e., those that can be directly manipulated (intervened upon) through actuation. Interventional CRL theory shows that variables that undergo variations via interventions can be identified. In robotics, such interventions arise naturally by commanding actuators of various joints and recording images under varied controls. Empirical evaluations in semi-synthetic manipulator experiments demonstrate that ROPES successfully disentangles latent generative factors with high fidelity with respect to the ground truth. Crucially, this is achieved by leveraging only distributional changes, without using any labeled data. The paper also includes a comparison with a baseline based on a recently proposed semi-supervised framework. This paper concludes by positioning robot pose estimation as a near-practical testbed for CRL.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">kulkarni2025ropes</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{ROPES}: Robotic Pose Estimation via Score-based Causal Representation Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kulkarni, Pranamya Prashant and Datta, Puranjay and Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv:2510.20884, (NeurIPS 2025 Workshop on Embodied World Models for Decision Making)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li><div class="row" style="margin-bottom: 30px;"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/umni_crl_thumbnail2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/umni_crl_thumbnail2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/umni_crl_thumbnail2-1400.webp"></source> <img src="/assets/img/publication_preview/umni_crl_thumbnail2.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="umni_crl_thumbnail2.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="varici2024linear" class="col-sm-8"> <div class="title">Linear Causal Representation Learning from Unknown Multi-node Interventions</div> <div class="author"> <em>Burak Varıcı</em>, Emre Acartürk, Karthikeyan Shanmugam, and Ali Tajer </div> <div class="periodical"> <em>In Proc. Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.05937" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/acarturk-e/score-based-crl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/UMN_CRL_poster_final.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://neurips.cc/media/neurips-2024/Slides/93136.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="abstract hidden"> <p>Despite the multifaceted recent advances in interventional causal representation learning (CRL), they primarily focus on the stylized assumption of single-node interventions. This assumption is not valid in a wide range of applications, and generally, the subset of nodes intervened in an interventional environment is fully unknown. This paper focuses on interventional CRL under unknown multi-node (UMN) interventional environments and establishes the first identifiability results for general latent causal models (parametric or nonparametric) under stochastic interventions (soft or hard) and linear transformation from the latent to observed space. Specifically, it is established that given sufficiently diverse interventional environments, (i) identifiability up to ancestors is possible using only soft interventions, and (ii) perfect identifiability is possible using hard interventions. Remarkably, these guarantees match the best-known results for more restrictive single-node interventions. Furthermore, CRL algorithms are also provided that achieve the identifiability guarantees. A central step in designing these algorithms is establishing the relationships between UMN interventional CRL and score functions associated with the statistical models of different interventional environments. Establishing these relationships also serves as constructive proof of the identifiability guarantees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">varici2024linear</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Linear Causal Representation Learning from Unknown Multi-node Interventions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">video_short</span> <span class="p">=</span> <span class="s">{https://neurips.cc/virtual/2024/poster/93136}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> <li><div class="row" style="margin-bottom: 30px;"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/finite_sample_crl_experiment-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/finite_sample_crl_experiment-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/finite_sample_crl_experiment-1400.webp"></source> <img src="/assets/img/publication_preview/finite_sample_crl_experiment.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="finite_sample_crl_experiment.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="acarturk2024sample" class="col-sm-8"> <div class="title">Sample Complexity of Interventional Causal Representation Learning</div> <div class="author"> Emre Acartürk, <em>Burak Varıcı</em>, Karthikeyan Shanmugam, and Ali Tajer </div> <div class="periodical"> <em>In Proc. Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=XL9aaXl0u6&amp;noteId=0uxPDmh1nn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/Finite_sample_CRL_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Consider a data-generation process that transforms low-dimensional latent causally-related variables to high-dimensional observed variables. Causal representation learning (CRL) is the process of using the observed data to recover the latent causal variables and the causal structure among them. Despite the multitude of identifiability results under various interventional CRL settings, the existing guarantees apply exclusively to the infinite-sample regime (i.e., infinite observed samples). This paper establishes the first sample-complexity analysis for the finite-sample regime, in which the interactions between the number of observed samples and probabilistic guarantees on recovering the latent variables and structure are established. This paper focuses on general latent causal models, stochastic soft interventions, and a linear transformation from the latent to the observation space. The identifiability results ensure graph recovery up to ancestors and latent variables recovery up to mixing with parent variables. Specifically, \(O((\log \frac{1}δ)^4)\)samples suffice for latent graph recovery up to ancestors with probability \(1 - δ\), and \(\cal O((\frac{1}{ε}\log \frac1δ)^4)\)samples suffice for latent causal variables recovery that is \(ε\)close to the identifiability class with probability \(1 - δ\).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">acarturk2024sample</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sample Complexity of Interventional Causal Representation Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Acart{\"u}rk, Emre and Var{\i}c{\i}, Burak and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> <li><div class="row" style="margin-bottom: 30px;"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AISTATS (oral)</abbr> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/aistats24_crl_thumbnail3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/aistats24_crl_thumbnail3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/aistats24_crl_thumbnail3-1400.webp"></source> <img src="/assets/img/publication_preview/aistats24_crl_thumbnail3.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="aistats24_crl_thumbnail3.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="varici2024general" class="col-sm-8"> <div class="title">General Identifiability and Achievability for Causal Representation Learning</div> <div class="author"> <em>Burak Varıcı</em>, Emre Acartürk, Karthikeyan Shanmugam, and Ali Tajer </div> <div class="periodical"> <em>In Proc. International Conference on Artificial Intelligence and Statistics</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v238/varici24a/varici24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/acarturk-e/score-based-crl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/AISTATS_CRL_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://virtual.aistats.org/media/aistats-2024/Slides/6689.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="abstract hidden"> <p>This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">varici2024general</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{General Identifiability and Achievability for Causal Representation Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Valencia, Spain}</span><span class="p">,</span>
  <span class="na">rank</span> <span class="p">=</span> <span class="s">{5}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li><div class="row" style="margin-bottom: 30px;"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> </div> <div id="varici2023score" class="col-sm-8"> <div class="title">Score-based causal representation learning with interventions</div> <div class="author"> <em>Burak Varıcı</em>, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, and Ali Tajer </div> <div class="periodical"> <em>arXiv:2301.08230</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Varici2023-score-arxiv.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Varici2023-CRL-workshop-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>This paper studies the causal representation learning problem when the latent causal variables are observed indirectly through an unknown linear transformation. The objectives are: (i) recovering the unknown linear transformation (up to scaling) and (ii) determining the directed acyclic graph (DAG) underlying the latent variables. Sufficient conditions for DAG recovery are established, and it is shown that a large class of non-linear models in the latent space (e.g., causal mechanisms parameterized by two-layer neural networks) satisfy these conditions. These sufficient conditions ensure that the effect of an intervention can be detected correctly from changes in the score. Capitalizing on this property, recovering a valid transformation is facilitated by the following key property: any valid transformation renders latent variables’ score function to necessarily have the minimal variations across different interventional environments. This property is leveraged for perfect recovery of the latent DAG structure using only soft interventions. For the special case of stochastic hard interventions, with an additional hypothesis testing step, one can also uniquely recover the linear transformation up to scaling and a valid causal ordering.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">varici2023score</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Score-based causal representation learning with interventions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acartürk, Emre and Shanmugam, Karthikeyan and Kumar, Abhishek and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv:2301.08230}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li></ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Burak Varıcı. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>