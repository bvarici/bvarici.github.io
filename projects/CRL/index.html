<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Score-based Causal Representation Learning | Burak Varıcı</title> <meta name="author" content="Burak Varıcı"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bvarici.github.io/projects/CRL/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Burak Varıcı</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/Varici_CV.pdf" target="_blank" rel="noopener noreferrer">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Score-based Causal Representation Learning</h1> <p class="post-description"></p> </header> <article> <style>.button-link{display:inline-block;padding:8px 16px;margin:6px;font-size:14px;font-weight:bold;color:#6a0dad;text-decoration:none;background:transparent;border:2px solid #6a0dad;border-radius:6px;transition:all .3s ease}.button-link:hover{background:#6a0dad;color:white;box-shadow:0 3px 5px rgba(0,0,0,0.15);transform:translateY(-1px)}.button-container{text-align:center;margin-top:20px}</style> <ul> <li><span style="font-size: 24px;"><strong>(AAAI 2025 Tutorial)</strong> Causal Representation Learning</span></li> </ul> <!--[[slides]](https://www.isg-rpi.com/_files/ugd/601e73_ccf7870865a74aa0b7f4fdc6660a168e.pdf)--> <div class="button-container"> <a href="https://www.isg-rpi.com/_files/ugd/601e73_ccf7870865a74aa0b7f4fdc6660a168e.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Slides</a> </div> <ul> <li><span style="font-size: 24px;"><strong>(North American School of Information Theory (NASIT) 2025 Tutorial)</strong> Causal Representation Learning</span></li> </ul> <div class="button-container"> <a href="https://drive.google.com/file/d/1ew-BWBPFBziI_Au52i1MtRSlrFKnSFdZ/view" class="button-link" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://mediaspace.umn.edu/media/1_thnye7es" class="button-link" rel="external nofollow noopener" target="_blank">Video Part 1</a> <a href="https://mediaspace.umn.edu/media/1_468pa4d9" class="button-link" rel="external nofollow noopener" target="_blank">Video Part 2</a> </div> <ul> <li><span style="font-size: 24px;"><strong>(JMLR 2025)</strong> Score-based Causal Representation Learning: Linear and General Transformations</span></li> </ul> <!--[[Paper]](https://www.jmlr.org/papers/volume26/24-0194/24-0194.pdf) [[Code]](https://github.com/acarturk-e/score-based-crl)--> <div class="button-container"> <a href="https://www.jmlr.org/papers/volume26/24-0194/24-0194.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> </div> <p>TLDR:</p> <ul> <li> <strong>Linear transform</strong>, general causal models, one single-node intervention per node.</li> <li> <em>Hard</em> interventions: element-wise identifiability up to scaling and perfect recovery of DAG.</li> <li> <em>Soft</em> interventions: identifiability up to ancestors. If the causal model is sufficiently nonlinear, then the latent DAG is fully identified and the latent variables are identified up to surrounding variables (shown to be a tight result)</li> <li> <strong>General transform</strong>: extended results upon the AISTATS paper, two single-node hard interventions per node suffice for element-wise identifiability (up to an intervible transform)</li> <li>First provably correct algorithm for general transforms! Experiments with images confirm the scalability.</li> <li>Benefits: do not require faithfulness assumption of causal discovery, and do not require knowing which pair of environments intervene on the same node.</li> <li>Partial Identifiability: can recover a single latent variable given interventions upon said variable (i.e. without requiring exhaustive interventions)</li> <li> <p>Intervention extrapolation: score-matching enables extrapolating to <em>unseen</em> interventions</p> </li> <li><span style="font-size: 24px;"><strong>(NeurIPS 2024)</strong> Linear Causal Representation Learning from Unknown Multi-node Interventions</span></li> </ul> <!--[[Paper]](https://openreview.net/forum?id=weemASPtzg) [[Code]](https://github.com/acarturk-e/score-based-crl) [[Poster]](https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/UMN_CRL_poster_final.pdf)--> <div class="button-container"> <a href="https://openreview.net/forum?id=weemASPtzg" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/UMN_CRL_poster_final.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Poster</a> </div> <p>TLDR:</p> <ul> <li>Linear transform, general causal models, <strong>unknown multi-node</strong> interventions. Same guarantees as single-node interventions!</li> <li> <strong>Hard</strong> interventions: element-wise identifiability up to scaling and perfect recovery of DAG.</li> <li> <strong>Soft</strong> interventions: identifiability up to ancestors</li> <li> <p>Requirement: multi-node interventions are diverse enough, specified as having a full-rank intervention signature matrix.</p> </li> <li><span style="font-size: 24px;"><strong>(NeurIPS 2024)</strong> Sample Complexity of Interventional Causal Representation Learning</span></li> </ul> <!--[[Paper]](https://openreview.net/forum?id=XL9aaXl0u6&noteId=0uxPDmh1nn) [[Poster]](https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/Finite_sample_CRL_poster.pdf)--> <div class="button-container"> <a href="https://openreview.net/forum?id=XL9aaXl0u6&amp;noteId=0uxPDmh1nn" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/Finite_sample_CRL_poster.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Poster</a> </div> <p>TLDR:</p> <ul> <li>Linear transform, general causal models, one <strong>single-node</strong> soft intervention per node.</li> <li>First sample complexity results for interventional CRL!</li> <li>Probably approximately correct (PAC)-identifiability via generic score estimators.</li> <li> <p>Specific sample complexity results for an RKHS-based score estimator.</p> </li> <li><span style="font-size: 24px;">General Identifiability and Achievability for Causal Representation Learning (AISTATS 2024 - oral)</span></li> </ul> <!--[Paper](https://proceedings.mlr.press/v238/varici24a.html) [[Code]](https://github.com/acarturk-e/score-based-CRL) [[Talk]](https://neurips.cc/virtual/2023/74252) [[Poster]](https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/AISTATS_CRL_poster.pdf)--> <div class="button-container"> <a href="https://proceedings.mlr.press/v238/varici24a.html" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://neurips.cc/virtual/2023/74252" class="button-link" rel="external nofollow noopener" target="_blank">Talk</a> <a href="https://github.com/bvarici/bvarici.github.io/blob/master/assets/pdf/AISTATS_CRL_poster.pdf" class="button-link" rel="external nofollow noopener" target="_blank">Poster</a> </div> <p>TLDR:</p> <ul> <li> <strong>General transform</strong>, general causal models, two single-node hard interventions per node suffice for element-wise identifiability (up to an intervible transform)!</li> <li>First provably correct algorithm for general transforms! Experiments with images confirm the scalability.</li> <li> <p>Benefits: do not require faithfulness assumption of causal discovery, and do not require to know which pair of environments intervene on the same node.</p> </li> <li><span style="font-size: 24px;">Score-based Causal Representation Learning with Interventions</span></li> </ul> <!--[[Paper]](https://arxiv.org/abs/2301.08230)--> <div class="button-container"> <a href="https://arxiv.org/abs/2301.08230" class="button-link" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/acarturk-e/score-based-crl" class="button-link" rel="external nofollow noopener" target="_blank">Code</a> </div> <p>=======================</p> <h3 id="project-summary">Project summary:</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/CRL_problem-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/CRL_problem-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/CRL_problem-1400.webp"></source> <img src="/assets/img/crl_figures/CRL_problem.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>In causal representation learning (CRL), we consider a data-generating process in which the high-dimensional observations \(X\) are generated from low-dimensional, causaly-related variables \(Z\) through an unknown transformation \(g\) as \(X=g(Z)\). The causal relationships among the latent variables are captured by a directed acyclic graph (DAG) \({\cal{G}}_{Z}\) over \(Z\).</p> <p>CRL is the process of inverting the data generation-process for using the observed data \(X\) and recovering (i) the causal structure \(\cal{G}_{Z}\) and (ii) the latent causal variables \(Z\). We focus on two central questions:</p> <ol> <li> <p><strong>Identifiability</strong>: Determining the necessary and sufficient conditions under which \({\cal{G}}_{Z}\) and \(Z\) can be recovered. The scope of identifiability (e.g., perfect or partial) critically depends on the extent of information available about the data and the underlying data-generation process.</p> </li> <li> <p><strong>Achievability</strong>: Designing algorithms that can recover \(Z\) and \(\mathcal{G}_{Z}\), while maintaining identifiability guarantees. Note that identifiability results can be non-constructive as well, without specifying feasible algorithms. Hence, we make the distinction and aim to design practical algorithms for achieving constructive identifiability results.</p> </li> </ol> <p><strong>Why is identifiability difficult?</strong> Identifiability is known to be impossible without additional supervision or sufficient statistical diversity among the samples of the observed data \(X\). For instance, for the true transform \(g\) and another invertible function \(a\), we have \((g \circ g^{-1})(X)=X\) and \((g \circ a^{-1}) \circ (a \circ g^{-1})(X)=X\). Hence, inverse transform \(g^{-1}\) cannot via ensuring reconstruction of \(X\). As an extreme simplification, linear mixing of <em>independent</em> Gaussian variables (i.e., a graph with no edge). Since Gaussians are rotation-invariant, we cannot distinguish between \(Z\) and \(R \circ Z\) for any rotation matrix \(R\).</p> <p>Therefore, to ensure identifiability, we need to look for a reasonable combination of (i) assumptions on the data-generation (model class we consider), and (ii) richer observations.</p> <h3 id="interventional-crl">Interventional CRL</h3> <p>In our work, we rely on <em>interventions</em> on the latent causal space to provide richer observations and sufficient statistical diversity to enable identifiability. Specifically, in addition to observational environment, we consider a set of given interventional environments, in which a subset of nodes are intervened in each. In this framework, we only use <em>distribution level</em> information, meaning that we use the interventions as a weak form of supervision via having access to only the pair of distributions before and after an intervention (as opposed to requiring pairs of observed and intervened samples). This allows us:</p> <ul> <li>model distribution shifts via changes in causal mechanisms</li> <li>contrast interventional vs. observational distributions</li> <li>if changes are sparse, gives a natural way to restrain the solution set</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/interventional_environments-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/interventional_environments-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/interventional_environments-1400.webp"></source> <img src="/assets/img/crl_figures/interventional_environments.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Ideally, one would prefer no restriction on intervention size, type, or knowledge. In our papers, we consider different settings, e.g. single-node vs. multi-node interventions and soft vs. hard interventions.</p> <h3 id="score-based-methodology">Score-based methodology</h3> <p>In our papers, we establish the connections between <strong>score functions</strong> (gradient of the log-density) and interventional distributions. Specifically, we show that differences in score functions across different environment pairs contain all the information about the latent DAG. Leveraging this property, we show that the data-generating process can be inverted by finding the inverse transform that minimizes the score differences in the latent space. Using this approach, we develop constructive proofs of identifiability and algorithms in various settings. To give an insight, there are two key properties of score functions that make this idea work. Denote \(s(z) = \nabla \log_z p(z)\) and \(s_X(x) = \nabla \log_x p(x)\) for observational distributions \(p(z)\) and \(p_X(x)\). Use superscript \(^m\) to denote corresponding definitions in interventional environment \({\cal E}^m\).</p> <ul> <li> <strong>Score differences are sparse</strong>: Consider a single-node intervention, e.g., node $i$ is intervened in \({\cal E}^m\). Then, the score difference function \(s(z) - s^m(z)\) will be sparse, with indices of non-zero entries exactly correspond to the parents of the intervened node. This implies that given access to all single-node interventions, changes in the score functions exactly give DAG structure!</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/intervention_score_connection-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/intervention_score_connection-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/intervention_score_connection-1400.webp"></source> <img src="/assets/img/crl_figures/intervention_score_connection.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>How we use this property to guide our learning of an inverse transform? Consider a candidate encoder $h$, and \let $\hat{Z} = h(X)$. Intuitively, we can use the sparsity of the <em>true latent score differences</em> to find the true encoder \(g^{-1}\), i.e., the estimated latent score differences cannot be sparser than the true score differences.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crl_figures/intuition-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crl_figures/intuition-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crl_figures/intuition-1400.webp"></source> <img src="/assets/img/crl_figures/intuition.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <strong>Latent score differences can be computed from observed score differences</strong>: So far, all the nice properties of score functions above are for latent variables, since these properties stem from the causal relationships among the latents and the interventions. However, we have only access to observed \(X\) variables. In terms of pure identifiability objective, one can suggest computing the score functions of $\hat{Z}$ for every possible encoder \(h\), which is infeasible. Instead, we take a constructive approach and show that latent score differences can be computed from observed score differences using the Jacobian of \(h^{-1}\). Specifically, \(s_{\hat{Z}} ({\hat{z}}) - s_{\hat{Z}}^{m}({\hat{z}}) = J_{h^{-1}}({\hat{z}})^{\top} (s_{X} (x) - s_{X}^{m}(x))\).</li> </ul> </article> <h2>References</h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div id="varici2023score" class="col-sm-8"> <div class="title">Score-based causal representation learning with interventions</div> <div class="author"> <b>Burak Varıcı</b>, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, and Ali Tajer</div> <div class="periodical"> <em>arXiv:2301.08230</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Varici2023-score-arxiv.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Varici2023-CRL-workshop-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>This paper studies the causal representation learning problem when the latent causal variables are observed indirectly through an unknown linear transformation. The objectives are: (i) recovering the unknown linear transformation (up to scaling) and (ii) determining the directed acyclic graph (DAG) underlying the latent variables. Sufficient conditions for DAG recovery are established, and it is shown that a large class of non-linear models in the latent space (e.g., causal mechanisms parameterized by two-layer neural networks) satisfy these conditions. These sufficient conditions ensure that the effect of an intervention can be detected correctly from changes in the score. Capitalizing on this property, recovering a valid transformation is facilitated by the following key property: any valid transformation renders latent variables’ score function to necessarily have the minimal variations across different interventional environments. This property is leveraged for perfect recovery of the latent DAG structure using only soft interventions. For the special case of stochastic hard interventions, with an additional hypothesis testing step, one can also uniquely recover the linear transformation up to scaling and a valid causal ordering.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">varici2023score</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Score-based causal representation learning with interventions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acartürk, Emre and Shanmugam, Karthikeyan and Kumar, Abhishek and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv:2301.08230}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="varici2024linear" class="col-sm-8"> <div class="title">Linear Causal Representation Learning from Unknown Multi-node Interventions</div> <div class="author"> <b>Burak Varıcı</b>, Emre Acartürk, Karthikeyan Shanmugam, and Ali Tajer</div> <div class="periodical"> <em>In Proc. Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.05937" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/acarturk-e/score-based-crl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/UMN_CRL_poster_final.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://neurips.cc/media/neurips-2024/Slides/93136.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="abstract hidden"> <p>Despite the multifaceted recent advances in interventional causal representation learning (CRL), they primarily focus on the stylized assumption of single-node interventions. This assumption is not valid in a wide range of applications, and generally, the subset of nodes intervened in an interventional environment is fully unknown. This paper focuses on interventional CRL under unknown multi-node (UMN) interventional environments and establishes the first identifiability results for general latent causal models (parametric or nonparametric) under stochastic interventions (soft or hard) and linear transformation from the latent to observed space. Specifically, it is established that given sufficiently diverse interventional environments, (i) identifiability up to ancestors is possible using only soft interventions, and (ii) perfect identifiability is possible using hard interventions. Remarkably, these guarantees match the best-known results for more restrictive single-node interventions. Furthermore, CRL algorithms are also provided that achieve the identifiability guarantees. A central step in designing these algorithms is establishing the relationships between UMN interventional CRL and score functions associated with the statistical models of different interventional environments. Establishing these relationships also serves as constructive proof of the identifiability guarantees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">varici2024linear</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Linear Causal Representation Learning from Unknown Multi-node Interventions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">video_short</span> <span class="p">=</span> <span class="s">{https://neurips.cc/virtual/2024/poster/93136}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="acarturk2024sample" class="col-sm-8"> <div class="title">Sample Complexity of Interventional Causal Representation Learning</div> <div class="author"> Emre Acartürk, <b>Burak Varıcı</b>, Karthikeyan Shanmugam, and Ali Tajer</div> <div class="periodical"> <em>In Proc. Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=XL9aaXl0u6&amp;noteId=0uxPDmh1nn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/Finite_sample_CRL_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">acarturk2024sample</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sample Complexity of Interventional Causal Representation Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Acart{\"u}rk, Emre and Var{\i}c{\i}, Burak and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AISTATS (oral)</abbr></div> <div id="varici2024general" class="col-sm-8"> <div class="title">General Identifiability and Achievability for Causal Representation Learning</div> <div class="author"> <b>Burak Varıcı</b>, Emre Acartürk, Karthikeyan Shanmugam, and Ali Tajer</div> <div class="periodical"> <em>In Proc. International Conference on Artificial Intelligence and Statistics</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v238/varici24a/varici24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/acarturk-e/score-based-crl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/AISTATS_CRL_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://virtual.aistats.org/media/aistats-2024/Slides/6689.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="abstract hidden"> <p>This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">varici2024general</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{General Identifiability and Achievability for Causal Representation Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Valencia, Spain}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">JMLR</abbr></div> <div id="varici2025score" class="col-sm-8"> <div class="title">Score-based causal representation learning: Linear and General Transformations</div> <div class="author"> <b>Burak Varıcı</b>, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, and Ali Tajer</div> <div class="periodical"> <em>Journal of Machine Learning Research</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://jmlr.org/papers/volume26/24-0194/24-0194.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/acarturk-e/score-based-crl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">varici2025score</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Score-based causal representation learning: Linear and General Transformations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Kumar, Abhishek and Tajer, Ali}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{26}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{112}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--90}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Burak Varıcı. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>