@inproceedings{varici2021learning,
  abbr={AISTATS},
  title={Learning Shared Subgraphs in Ising Model Pairs},
  author={Var{\i}c{\i}, Burak and Sihag, Saurabh and Tajer, Ali},
  booktitle={Proc. International Conference on Artificial Intelligence and Statistics},
  pages={3952--3960},
  year={2021},
  bibtex_show={true},
  pdf={Varici2021-AISTATS.pdf},
  poster={Varici2021-AISTATS-poster.pdf}
}


@inproceedings{varici2021scalable,
  abbr={NeurIPS},
  title={Scalable Intervention Target Estimation in Linear Models},
  author={Var{\i}c{\i}, Burak and Shanmugam, Karthikeyan and Sattigeri, Prasanna and Tajer, Ali},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  year={2021},
  pages = {1494--1505},
  bibtex_show={true},
  pdf={Varici2021-NeurIPS.pdf},
  poster={Varici2021-NeurIPS-poster.pdf},
  code={https://github.com/bvarici/intervention-estimation}
}


@inproceedings{varici2022intervention,
  abbr={UAI},
  title =    {Intervention target estimation in the presence of latent variables},
  author =       {Var{\i}c{\i}, Burak and Shanmugam, Karthikeyan and Sattigeri, Prasanna and Tajer, Ali},
  booktitle =    {Proc. Conference on Uncertainty in Artificial Intelligence},
  pages =    {2013--2023},
  year =   {2022},
  address = {Eindhoven, Netherlands},
  bibtex_show={true},
  pdf = {Varici2022-UAI.pdf},
  poster = {Varici2022-UAI-poster.pdf},
  code = {https://github.com/bvarici/uai2022-intervention-estimation-latents}
}

@article{varici2023causal,
  abbr={JMLR},
  author  = {Burak Var{\i}c{\i} and Karthikeyan Shanmugam and Prasanna Sattigeri and Ali Tajer},
  title   = {Causal Bandits for Linear Structural Equation Models},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {297},
  pages   = {1--59},
  bibtex_show={true},
  url     = {http://jmlr.org/papers/v24/22-0969.html},
  pdf = {https://jmlr.org/papers/volume24/22-0969/22-0969.pdf},
  code = {https://github.com/bvarici/causal-bandits-linear-sem},
  poster = {JMLR_causal_bandits_poster.pdf}
}

@article{varici2023score,
  abbr={arXiv},
  title={Score-based causal representation learning with interventions},
  author={Var{\i}c{\i}, Burak and Acart√ºrk, Emre and Shanmugam, Karthikeyan and Kumar, Abhishek and Tajer, Ali},
  journal={arXiv:2301.08230},
  year={2023},
  pdf={Varici2023-score-arxiv.pdf},
  bibtex_show={true},
  slides={Varici2023-CRL-workshop-slides.pdf}
}


@inproceedings{varici2024linear,
  abbr = {NeurIPS},
  title={Linear Causal Representation Learning from Unknown Multi-node Interventions},
  author={Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali},
  booktitle={Proc. Advances in Neural Information Processing Systems},    
  year={2024},
  pdf={https://arxiv.org/abs/2406.05937},
  bibtex_show={true},
  code = {https://github.com/acarturk-e/umni-crl},
  poster={UMN_CRL_poster_final.pdf},
  abstract={Despite the multifaceted recent advances in interventional causal representation learning (CRL), they primarily focus on the stylized assumption of single-node interventions. This assumption is not valid in a wide range of applications, and generally, the subset of nodes intervened in an interventional environment is fully unknown. This paper focuses on interventional CRL under unknown multi-node (UMN) interventional environments and establishes the first identifiability results for general latent causal models (parametric or nonparametric) under stochastic interventions (soft or hard) and linear transformation from the latent to observed space. Specifically, it is established that given sufficiently diverse interventional environments, (i) identifiability up to ancestors is possible using only soft interventions, and (ii) perfect identifiability is possible using hard interventions. Remarkably, these guarantees match the best-known results for more restrictive single-node interventions. Furthermore, CRL algorithms are also provided that achieve the identifiability guarantees. A central step in designing these algorithms is establishing the relationships between UMN interventional CRL and score functions associated with the statistical models of different interventional environments. Establishing these relationships also serves as constructive proof of the identifiability guarantees.}
}

@inproceedings{varici2024interventional,
  abbr={NeurIPS},
  title={Interventional Causal Discovery in a Mixture of DAGs},
  author={Var{\i}c{\i}, Burak and Katz, Dmitriy A and Wei, Dennis and Sattigeri, Prasanna and Tajer, Ali},
  booktitle={Proc. Advances in Neural Information Processing Systems},    
  year={2024},
  pdf={https://arxiv.org/abs/2406.08666},
  bibtex_show={true},
  code={https://github.com/bvarici/intervention-mixture-DAG},
  poster={Int_Mixture_DAG_poster_final.pdf},
  abstract={Causal interactions among a group of variables are often modeled by a single causal graph. In some domains, however, these interactions are best described by multiple co-existing causal graphs, e.g., in dynamical systems or genomics. This paper addresses the hitherto unknown role of interventions in learning causal interactions among variables governed by a mixture of causal systems, each modeled by one directed acyclic graph (DAG). Causal discovery from mixtures is fundamentally more challenging than single-DAG causal discovery. Two major difficulties stem from (i) an inherent uncertainty about the skeletons of the component DAGs that constitute the mixture and (ii) possibly cyclic relationships across these component DAGs. This paper addresses these challenges and aims to identify edges that exist in at least one component DAG of the mixture, referred to as the true edges. First, it establishes matching necessary and sufficient conditions on the size of interventions required to identify the true edges. Next, guided by the necessity results, an adaptive algorithm is designed that learns all true edges using $O(n^2)$ interventions, where $n$ is the number of nodes. Remarkably, the size of the interventions is optimal if the underlying mixture model does not contain cycles across its components. More generally, the gap between the intervention size used by the algorithm and the optimal size is quantified. It is shown to be bounded by the cyclic complexity number of the mixture model, defined as the size of the minimal intervention that can break the cycles in the mixture, which is upper bounded by the number of cycles among the ancestors of a node.}
}

@inproceedings{acarturk2024sample,
  abbr={NeurIPS},
  title={Sample Complexity of Interventional Causal Representation Learning},
  author={Acart{\"u}rk, Emre and Var{\i}c{\i}, Burak and Shanmugam, Karthikeyan and Tajer, Ali},
  booktitle={Proc. Advances in Neural Information Processing Systems},    
  year={2024},
  pdf={https://openreview.net/forum?id=XL9aaXl0u6&noteId=0uxPDmh1nn},
  bibtex_show={true},
  abstract={   Consider a data-generation process that transforms low-dimensional \emph{latent} causally-related variables to high-dimensional \emph{observed} variables. Causal representation learning (CRL) is the process of using the observed data to recover the latent causal variables and the causal structure among them. Despite the multitude of identifiability results under various interventional CRL settings, the existing guarantees apply exclusively to the \emph{infinite-sample} regime (i.e., infinite observed samples). This paper establishes the first sample-complexity analysis for the finite-sample regime, in which the interactions between the number of observed samples and probabilistic guarantees on recovering the latent variables and structure are established. This paper focuses on \emph{general} latent causal models, stochastic \emph{soft} interventions, and a linear transformation from the latent to the observation space. The identifiability results ensure graph recovery up to ancestors and latent variables recovery up to mixing with parent variables. Specifically, ${\cal O}((\log \frac{1}{\delta})^{4})$ samples suffice for latent graph recovery up to ancestors with probability $1 - \delta$, and ${\cal O}((\frac{1}{\epsilon}\log \frac{1}{\delta})^{4})$ samples suffice for latent causal variables recovery that is $\epsilon$ close to the identifiability class with probability $1 - \delta$.}
}

@inproceedings{varici2024general,
  abbr={AISTATS (oral)},
  title={General Identifiability and Achievability for Causal Representation Learning},
  author={Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali},
  booktitle = 	 {Proc. International Conference on Artificial Intelligence and Statistics},
  year={2024},
  address={Valencia, Spain},
  pdf={https://proceedings.mlr.press/v238/varici24a/varici24a.pdf},
  bibtex_show={true},
  code = {https://github.com/bvarici/score-general-id-CRL},
  poster={AISTATS_CRL_poster.pdf},
  slides={https://virtual.aistats.org/media/aistats-2024/Slides/6689.pdf},
  abstract={This paper focuses on causal representation
learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to
the observational data. It establishes identifiability and achievability results using
two hard uncoupled interventions per node
in the latent causal graph. Notably, one does
not know which pair of intervention environments have the same node intervened (hence,
uncoupled). For identifiability, the paper establishes that perfect recovery of the latent
causal model and variables is guaranteed under uncoupled interventions. For achievability,
an algorithm is designed that uses observational and interventional data and recovers
the latent causal model and variables with
provable guarantees. This algorithm leverages
score variations across different environments
to estimate the inverse of the transformer and,
subsequently, the latent variables. The analysis, additionally, recovers the identifiability
result for two hard coupled interventions,
that is when metadata about the pair of environments that have the same node intervened
is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the
existing literature are unnecessary.}
}

@article{varici2024score,
  abbr={arXiv},
  title={Score-based causal representation learning: Linear and General Transformations},
  author={Var{\i}c{\i}, Burak and Acart{\"u}rk, Emre and Shanmugam, Karthikeyan and Kumar, Abhishek and Tajer, Ali},
  journal={arXiv:2402.00849},
  year={2024},
  pdf={https://arxiv.org/abs/2402.00849},
  bibtex_show={true},
  code={https://github.com/acarturk-e/score-based-crl},
  abstract={This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.}
}

@article{varici2024separability,
  abbr={TMLR},
  title={Separability Analysis for Causal Discovery in Mixture of {DAG}s},
  author={Var{\i}c{\i}, Burak and Katz-Rogozhnikov, Dmitriy and Wei, Dennis and Sattigeri, Prasanna and Tajer, Ali},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2024},
  pdf={https://openreview.net/forum?id=ALRWXT1RLZ},
  bibtex_show={true},
  code={https://github.com/bvarici/TMLR-mixture-DAG},
  abstract={ Directed acyclic graphs (DAGs) are effective for compactly representing causal systems and specifying the causal relationships among the system's constituents. Specifying such causal relationships in some systems requires a mixture of multiple DAGs -- a single DAG is insufficient. Some examples include time-varying causal systems or aggregated subgroups of a population. Recovering the causal structure of the systems represented by single DAGs is investigated extensively, but it remains mainly open for the systems represented by a mixture of DAGs. A major difference between single- versus mixture-DAG recovery is the existence of node pairs that are separable in the individual DAGs but become inseparable in their mixture. This paper provides the theoretical foundations for analyzing such inseparable node pairs. Specifically, the notion of \emph{emergent edges} is introduced to represent such inseparable pairs that do not exist in the single DAGs but emerge in their mixtures. Necessary conditions for identifying the emergent edges are established. Operationally, these conditions serve as sufficient conditions for separating a pair of nodes in the mixture of DAGs. These results are further extended, and matching necessary and sufficient conditions for identifying the emergent edges in tree-structured DAGs are established. Finally, a novel graphical representation is formalized to specify these conditions, and an algorithm is provided for inferring the learnable causal relations.}
}

@article{yan2024robust,
  abbr={JSAIT},
  title={Robust Causal Bandits for Linear Models},
  author={Yan, Zirui and Mukherjee, Arpan and Var{\i}c{\i}, Burak and Tajer, Ali},
  journal={IEEE Journal on Selected Areas in Information Theory},
  year={2024},
  pdf={https://arxiv.org/pdf/2310.19794},
  bibtex_show={true}
}

@inproceedings{yan2024improved,
  abbr={ISIT},
  title={Improved Bound for Robust Causal Bandits with Linear Models},
  author={Yan, Zirui and Mukherjee, Arpan and Var{\i}c{\i}, Burak and Tajer, Ali},
  booktitle={International Symposium on Information Theory},
  year={2024},
  address={Athens, Greece},
  pdf={https://arxiv.org/pdf/2405.07795},
  bibtex_show={true}
}

